# 02 - NumPy (2)

## 一、爱因斯坦求和约定

对于矩阵运算，NumPy 还提供了 `einsum()` 方法，它根据爱因斯坦求和约定来执行一些求和操作。该方法并不是一个简单的求和运算方法，而是一个高效的符号计算规则，它可以实现矩阵的各种求和操作(如点乘、转置、矩阵求迹等)。在深度学习框架(如 TensorFlow 或 PyTorch)中，`einsum()` 还可以用与神经网络框架的任意计算图，并支持反向传播计算。

### 1. 爱因斯坦求和约定

爱因斯坦求和约定(Einstein summation convention)又称为爱因斯坦标记法(Einstein notation)，由物理学家阿尔伯特 · 爱因斯坦于 1916 年提出，在处理关于坐标的方程式时十分有用。

这种约定，简单来说就是省去了求和公式中的求和符号。对于下面的点乘公式：

$$
s = \sum_{i}\nu_i \omega_i
$$

这个公式表述的是，两个向量对应的元素相乘后再求和。爱因斯坦觉得这种数学符号过于繁琐，求和符号纯属多余，于是发明了另一种写法：

$$
s = \nu_i \omega^i
$$

在爱因斯坦的标记体系中，下标表示行向量中的元素：

$$
\begin{bmatrix}
 \nu _1 & \nu _2 & ... & \nu_k
\end{bmatrix}
$$

上标表示列向量中的元素：

$$\begin{bmatrix}
\omega ^1
 \\ \omega ^2
 \\ ...
 \\ \omega ^k

\end{bmatrix}
$$

类似的，矩阵 A 中第 m 行第 n 列的元素，以前标记为$A_{mn}$，现在标记为$A_n^m$。

下面列出用爱因斯坦标记法来表示的一般运算：

1.  内积(Inner product)：即数量积。

$$
{u}\cdot {\nu } = u_j\nu^i
$$

2.  向量乘以矩阵(Matrix-vector multiplication)：矩阵 A 乘以向量$\nu$。

$$
u^i = A_j^i\nu^j
$$

3.  矩阵乘法(Matrix multiplication)：矩阵$A_{i\times j}$与矩阵$B_{j\times k}$的乘法。

$$
C_{k}^j = A_j^iB_k^j
$$

4.  矩阵的迹(Trace)：$i\times i$的矩阵 A 的主对角线(左上角至右下角)上各元素的和。

$$
t = A_i^i
$$

5.  外积(Outer product)：M 维向量和 N 维向量的外积是一个$M\times N$的矩阵 A。

$$
A_j^i = a^ib_j
$$

### 2. NumPy 中的 `einsum()` 方法

`einsum()` 使用格式字符串来间接实现上下标的功能，从而实现求和、求内积、求外积、矩阵乘法、矩阵转置、求迹等操作。弱国分别使用 `sum()`、`mat()`、`trace()`、`tensordot()` 等方法来实现这些功能，不但方法名称复杂，额日期额对于高维张量，进行维度计算时很容易出错。

`einsum()` 方法的格式如下：

```python
einsum("格式字符1, 格式字符2, 格式字符3 -> 格式字符4", arg1, arg2, arg3)
```

理论上 `einsum()` 方法支持任意多的参数，该方法的第一个参数即格式字符串至关重要，直接决定这个方法实现的功能。格式字符串的规定如下：

- 不同的输入字符之间用逗号 `,` 隔开，输入字符与输出字符之间用箭头 `->` 隔开。
- 输入字符的数量要与参与运算的变量数量相匹配。
- 格式字符的字符数(字符串长度)和张量的维度相对应。

例如，对于指令 `einsum('ijk, ijl -> kl', a, b)`，可以知道张量 `a` 和 `b` 都是三维矩阵，计算结果是一个二维张量。

```python
import numpy as np

arr = np.arange(10)
sum = np.einsum('i ->', arr)        # 一维张量求和
print(sum)

# 45

arr2 = np.arange(20).reshape(4, 5)
sum2 = np.einsum('ij -> j', arr2)   # 二维张量按列求和
print(sum2)

# [30 34 38 42 46]
```

如果处理的张量维度很高，可以将多个维度用省略号替代，以表示剩下所有维度：

```python
result = np.einsum('i... -> ...', arr)  # 对arr进行降维求和
```

除了使用 `einsum()` 做加法，还可以做矩阵乘法。

```python
import numpy as np

a = np.arange(10).reshape(5, 2)
b = np.array([[2, 3, 4], [6, 7, 8]])
c = np.ones(shape=(2, 3))

result1 = np.einsum('ij, jk -> ik', a, b)   # 外积，等价于a @ b和np.dot(a, b)
print(result1)

# [[  6   7   8]
#  [ 22  27  32]
#  [ 38  47  56]
#  [ 54  67  80]
#  [ 70  87 104]]

result2 = np.einsum('ij, ij -> ij', b, c)   # 点乘，等价于a * b和np.multiply(a, b)
print(result2)

# [[2. 3. 4.]
#  [6. 7. 8.]]

result3 = np.einsum('ij, ij ->', b, c)      # 内积，等价于np.inner(a, b)
print(result3)

# 30.0

result4 = np.einsum('ii ->', np.arange(9).reshape(3, 3))    # 矩阵的迹
print(result4)

# 12

result5 = np.einsum('ij -> ji', a)          # 矩阵的转置
print(result5)

# [[0 2 4 6 8]
#  [1 3 5 7 9]]
```

## 二、NumPy 中的轴

在 NumPy 的多维数组中，常有“约减”(Reduce，也译作“规约”)的提法，表示将众多数据按照某一规则合并为一个或几个数据。约减之后，数据个数在总量上减少。例如，数组的加法操作是一种约减，求 N 维数组的均值 mean、最大值 max、最小值 min 等，都属于约减操作。

有时会有这样需求：对指定维度方向的值进行统计，如统计某一行的均值、最大值等。这时需要给“约减”指令指定方向。

事实上，`sum()`、`min()`、`max()`、`mean()` 等函数都有一个轴 `axis` 的参数，其默认值为 `None`，即不指定约减方向。

- `axis` 值为 0，表示从垂直方向进行约减。
- `axis` 值为 1，表示从水平方向进行约减。
